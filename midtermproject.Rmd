---
title: "SMA"
author: "Bolun Lin"
date: "2019年4月19日"
output: html_document
---

### 準備所需要的library
```{r message=FALSE, warning=FALSE}
packages = c("dplyr", "tidytext", "stringr", "wordcloud2","tidyverse",'knitr','kableExtra', "ggplot2",'readr','data.table','reshape2','wordcloud','tidyr','scales','jiebaR','sentimentr','htmltools')
existing = as.character(installed.packages()[,1])
for(pkg in packages[!(packages %in% existing)]) install.packages(pkg)
```
### 載入 library
```{r message=FALSE, warning=FALSE} 

library(dplyr)
library(stringr)
require(tidytext)
library(sentimentr)
library(wordcloud2)
require(data.table)
require(ggplot2)
require(reshape2)
require(wordcloud)
require(tidyr)
require(readr)
require(scales)
library(jiebaR)
library(tidyverse)
library(knitr)
library(kableExtra)
```

### 載入文章及留言
```{r}
nsysu_data = fread("data/my_csv_nsysu.csv",encoding = 'UTF-8')
nuk_data =fread("data/my_csv_nuk.csv",encoding = 'UTF-8')
exam_data =fread("data/my_csv_exam.csv",encoding = 'UTF-8')
ptt_data =fread("data/ptt.csv",encoding = 'UTF-8')
nsysu_comment =fread("data/comment_nsysu.csv",encoding = 'UTF-8') #552
nuk_comment =fread("data/comment_nuk.csv",encoding = 'UTF-8') #818
ptt_comment =fread("data/comment_ptt.csv",encoding = 'UTF-8') #1024
exam_comment =fread("data/comment_exam.csv",encoding = 'UTF-8') #1024
# apple_data =fread("data/merge_apple_articleMetaData.csv",encoding = 'UTF-8') #蘋果資料不佳
```

### 整理文章資料
```{r}
nsysu_data = nsysu_data %>%
  filter(grepl("高大|併校|合併|合校|高雄大學|公聽會",content)|grepl("高大|併校|合併|合校|高雄大學|公聽會",title))%>%
  mutate(source = "nsysu_dcard")
nuk_data = nuk_data %>%
   filter(grepl("中山|併校|合併|合校|中山大學|公聽會",content)|grepl("中山|併校|合併|合校|中山大學|公聽會",title)) %>%
  mutate(source = "nuk_dcard")

exam_data = exam_data %>%
   filter(grepl("併校|合併|合校|公聽會",content)|grepl("併校|合併|合校|公聽會",title)) %>%
   filter(grepl("高大|中山|高雄大學",content)|grepl("高大|中山|高雄大學",title)) %>%
  mutate(source = "exam_dcard")
ptt_data = ptt_data %>%
   filter(grepl("併校|合併|合校|公聽會",artTitle)|grepl("併校|合併|合校|公聽會",artContent)) %>%
   filter(grepl("高大|中山|高雄大學",artTitle)|grepl("高大|中山|高雄大學",artContent)) %>%
  mutate(source = "ptt")
colnames(ptt_data)[which(names(ptt_data) == "_id")] <- "id"

head(nuk_data,10)
head(nuk_data,10)
head(exam_data,10)
head(ptt_data,10)
```
 總共有 30篇dcard中山板的文、30篇高大板的文章、29篇ptt板的文章
### 將文章資料合在一起
```{r}
article = nsysu_data %>%
   select(id,createdAt ,source ,title,content)%>% 
   rbind(nuk_data %>% select(id,createdAt ,source ,title,content))%>%
   rbind(exam_data %>% select(id,createdAt ,source ,title,content))
colname = c("id", "artDate","source","artTitle","artContent")
colnames(article) <- colname
article = article %>%
  rbind(ptt_data %>% select(id,artDate ,source ,artTitle,artContent))

article$artDate = as.Date(article$artDate)
article
```
### 整理留言資料
```{r}
nsysu_comment = nsysu_comment %>%
  filter(nchar(nsysu_comment$content)>5)%>% #412
  mutate(source="nsysu_dcard")
 nuk_comment = nuk_comment %>%
  filter(nchar(nuk_comment$content)>5)%>% #501
   mutate(source="nuk_dcard")
 exam_comment = exam_comment %>%
  filter(nchar(exam_comment$content)>5)%>% #978
  mutate(source="exam_dcard")
ptt_comment = ptt_comment %>%
  filter(nchar(ptt_comment$content)>5)%>% #386
  mutate(source="ptt")
head(nsysu_comment,10)
head(nuk_comment,10)
head(exam_comment,10)
head(ptt_comment,10)
```
### 將留言資料合在一起
```{r}
comment = nsysu_comment %>%
   select(id,Date ,source ,source,content)%>% 
   rbind(nuk_comment %>% select(id,Date ,source ,content))%>%
  rbind(exam_comment %>% select(id,Date ,source ,content))

comment =comment %>%
  rbind(ptt_comment %>% select(id,Date ,source ,source,content))
colname = c("id", "artDate","source","artContent")
colnames(comment) <- colname
comment$artDate = as.Date(comment$artDate)
comment
```

```{r}
data_article <- article %>% 
  select(artDate, id,source) %>% 
  distinct()
data_comment <- comment %>% 
  select(artDate, id,source) %>% 
  distinct()
```


```{r}
article_count_by_date <- data_article %>% 
  group_by(artDate,source) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))
comment_count_by_date <- data_comment %>% 
  group_by(artDate,source) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))

head(article_count_by_date, 20)
head(comment_count_by_date, 20)
```

```{r}
plot_date <- 
  article_count_by_date %>% 
  ggplot(aes(x = artDate, y = count,colour=source)) +
  geom_line(size = 0.5) + 
  # geom_vline(xintercept = as.numeric(as.Date("2019-03-30")), col='red') + 
  scale_x_date(labels = date_format("%Y/%m/%d" )) +
  ggtitle("高大與中山併校 討論文章數") + 
  xlab("日期") + 
  ylab("數量") + 
  theme(text = element_text(family = "Heiti TC Light")) #加入中文字型設定，避免中文字顯示錯誤。

plot_date


plot_date <- 
  comment_count_by_date %>% 
  ggplot(aes(x = artDate, y = count,colour=source)) +
  geom_line(size = 0.5) + 
  # geom_vline(xintercept = as.numeric(as.Date("2019-03-30")), col='red') + 
  scale_x_date(labels = date_format("%Y/%m/%d" )) +
  ggtitle("高大與中山併校 討論留言數") + 
  xlab("日期") + 
  ylab("數量") + 
  theme(text = element_text(family = "Heiti TC Light")) #加入中文字型設定，避免中文字顯示錯誤。

plot_date

```



```{r}
jieba_tokenizer <- worker(user="dict/user_dict.txt", stop_word = "dict/stop_words.txt")
clean = function(txt) {
  txt = gsub("B\\w+", "", txt) #去除@或#後有數字,字母,底線 (標記人名或hashtag)
  txt = gsub("(http|https)://.*", "", txt) #去除網址
  txt = gsub("[ \t]{2,}", "", txt) #去除兩個以上空格或tab
  txt = gsub("\\n"," ",txt) #去除換行
  txt = gsub("\\s+"," ",txt) #去除一個或多個空格
  txt = gsub("^\\s+|\\s+$","",txt) #去除前後一個或多個空格
  txt = gsub("&.*;","",txt) #去除html特殊字元編碼
  txt = gsub("[a-zA-Z0-9?!. ']","",txt) #除了字母,數字 ?!. ,空白的都去掉
  txt }

tokenizer <- function(t) {
  lapply(t, function(x) {
    tokens <- segment(x, jieba_tokenizer)
    return(tokens)
  })
}
artilce_tokens <- article %>% 
  unnest_tokens(word, artContent, token=tokenizer)
artilce_tokens$word = clean(artilce_tokens$word)
artilce_tokens = artilce_tokens %>%
  filter(!word == "")

comment_tokens <- comment %>% 
  unnest_tokens(word, artContent, token=tokenizer)
comment_tokens$word = clean(comment_tokens$word)
comment_tokens = comment_tokens %>%
  filter(!word == "")
```
# 文字雲
```{r}
# 計算詞彙的出現次數，如果詞彙只有一個字則不列入計算
article_tokens_count <- artilce_tokens %>% 
  filter(nchar(.$word)>1) %>%
  group_by(word) %>% 
  summarise(sum = n()) %>% 
  filter(sum>1) %>%
  arrange(desc(sum))
comment_tokens_count <- comment_tokens %>% 
  filter(nchar(.$word)>1) %>%
  group_by(word) %>% 
  summarise(sum = n()) %>% 
  filter(sum>1) %>%
  arrange(desc(sum))
# 印出最常見的20個詞彙
head(article_tokens_count, 20)
head(comment_tokens_count, 20)

```
```{r}

article_tokens_count %>% wordcloud2()

comment_tokens_count %>% wordcloud2()

article_tokens_count %>%
  filter(!word %in% c("中山","大學","中山大學","高大","學校","高雄大學","國立","合校"))%>%
  mutate(word = reorder(word, sum)) %>%
  top_n(25,sum) %>%
  ggplot(aes(word, sum)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
comment_tokens_count %>%
  filter(!word %in% c("中山","大學","中山大學","高大","學校","高雄大學","國立","合校"))%>%
  mutate(word = reorder(word, sum)) %>%
  top_n(25,sum) %>%
  ggplot(aes(word, sum)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()


```

探討dcar上高大同學以及中山同學對於併校的看法
```{r}
library(gtools)
student_dcard =artilce_tokens %>%
  smartbind(comment_tokens)
student_dcard = student_dcard%>%
  filter(source %in% c("nsysu_dcard","nuk_dcard"))
  
student_dcard%>%
  group_by(source) %>% 
  summarise(sum = n()) %>%
  ggplot(aes(source,
             sum))+ 
  geom_bar(stat="identity", width=0.5,fill="steelblue")+
  geom_text(aes(label=sum), vjust=-0.3, size=3.5)
```
```{r}
frequency <- student_dcard%>%
  dplyr::count(source, word)%>%
  group_by(source) %>%
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  spread(source, proportion) %>% 
  gather(source, proportion, `nuk_dcard`)
frequency

```

```{r}
ggplot(frequency, aes(x = proportion, y = `nsysu_dcard`, color = abs(`nsysu_dcard` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.2, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75")+
  theme(legend.position="none") +
  labs(y = "nsysu_dcard", x = "nuk_dcard")
```

```{r}
cor.test(data = frequency[frequency$source == "nuk_dcard",],
         ~ proportion + `nsysu_dcard`)
```
#準備LIWC字典 
```{r}
p <- read_file("dict/positive.txt")
n <- read_file("dict/negative.txt")

positive <- strsplit(p, "[,]")[[1]]
negative <- strsplit(n, "[,]")[[1]]
positive <- data.frame(word = positive, sentiments = "positive")
negative <- data.frame(word = negative, sentiemtns = "negative")
colnames(negative) = c("word","sentiment")
colnames(positive) = c("word","sentiment")
LIWC_ch <- rbind(positive, negative)
LIWC_ch
```


## 情緒字典
```{r}
sentiment_dcard = student_dcard %>%
   filter(nchar(.$word)>1) %>%
  group_by(source,word) %>% 
  summarise(sum = n()) %>% 
  filter(sum>1) %>%
  arrange(desc(sum))%>%
  inner_join(LIWC_ch)
sentiment_dcard
student_dcard %>%
  inner_join(LIWC_ch)
```


```{r}
plot_table<-sentiment_dcard %>%
  group_by(source,sentiment) %>%
  summarise(count=sum(sum)) 

# interaction(source, sentiment)
plot_table %>%
  ggplot(aes( sentiment,count,fill=sentiment))+
  geom_bar(stat="identity", width=0.5)+
  facet_grid(~source)
```
看不出差異，手動增加字典

```{r}

```





