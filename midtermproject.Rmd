---
title: "SMA"
author: "Bolun Lin"
date: "2019年4月19日 "
output: 
  html_document:
    highlight: pygments
    theme: flatly
    css: style.css
---

### 系統設置
```{r}
Sys.setlocale("LC_CTYPE", "cht")
```



### 準備所需要的library
```{r message=FALSE, warning=FALSE}
 packages = c("dplyr", "tidytext", "stringr", "wordcloud2","tidyverse",'knitr','kableExtra','NLP', "ggplot2",'readr','data.table','reshape2','tidyr','scales','jiebaR','htmltools',"ggraph", "igraph", "reshape2", "widyr","gtools")
 existing = as.character(installed.packages()[,1])
 for(pkg in packages[!(packages %in% existing)]) install.packages(pkg)
```
### 載入 library
```{r message=FALSE, warning=FALSE} 
library(dplyr)
library(stringr)
require(tidytext)
library(wordcloud2)
require(data.table)
require(ggplot2)
require(reshape2)
require(tidyr)
require(readr)
require(scales)
library(jiebaR)
library(tidyverse)
library(knitr)
library(kableExtra)
library(NLP)
library(ggraph)
library(igraph)
library(reshape2)
library(widyr)
library(gtools)
library(htmltools)
```

### 載入文章及留言
- 資料來源:
  - dcard中山板、dcard高大板、dcard考試板各1000篇 約到去年10月
  - ptt八卦板 去年10月到2019/4/19
  - 分為文章以及留言，留言為過濾完的文章後的留言
```{r}

nsysu_data = fread("data/my_csv_nsysu.csv",encoding = 'UTF-8')
nuk_data =fread("data/my_csv_nuk.csv",encoding = 'UTF-8')
exam_data =fread("data/my_csv_exam.csv",encoding = 'UTF-8')
ptt_data =fread("data/ptt.csv",encoding = 'UTF-8')
nsysu_comment =fread("data/comment_nsysu.csv",encoding = 'UTF-8') #552
nuk_comment =fread("data/comment_nuk.csv",encoding = 'UTF-8') #818
ptt_comment =fread("data/comment_ptt.csv",encoding = 'UTF-8') #1024
exam_comment =fread("data/comment_exam.csv",encoding = 'UTF-8') #1024
```

### 整理文章資料
```{r}
#過濾有出現關於併校資訊關鍵字的文章，並且將增加來源的欄位
nsysu_data = nsysu_data %>%
  filter(grepl("高大|併校|合併|合校|高雄大學|公聽會",content)|grepl("高大|併校|合併|合校|高雄大學|公聽會",title))%>%
  mutate(source = "nsysu_dcard")
nuk_data = nuk_data %>%
   filter(grepl("中山|併校|合併|合校|中山大學|公聽會",content)|grepl("中山|併校|合併|合校|中山大學|公聽會",title)) %>%
   filter(!(grepl("愛滋",content)|grepl("愛滋",title))) %>%
   mutate(source = "nuk_dcard")
exam_data = exam_data %>%
   filter(grepl("併校|合併|合校|公聽會",content)|grepl("併校|合併|合校|公聽會",title)) %>%
   filter(grepl("高大|中山|高雄大學",content)|grepl("高大|中山|高雄大學",title)) %>%
  mutate(source = "exam_dcard")
ptt_data = ptt_data %>%
   filter(grepl("併校|合併|合校|公聽會",artTitle)|grepl("併校|合併|合校|公聽會",artContent)) %>%
   filter(grepl("高大|中山|高雄大學",artTitle)|grepl("高大|中山|高雄大學",artContent)) %>%
   filter(!(grepl("山手線|賽馬|手線|高雄縣市合併|又老又窮|清大或交大合校",artTitle)|grepl("山手線|賽馬|手線|大甲",artContent))) %>% 
  mutate(source = "ptt")
#將ptt的資料_id 改成統一的id
colnames(ptt_data)[which(names(ptt_data) == "_id")] <- "id"
```
- 總共有 30篇dcard中山板的文、34篇高大板的文章、13篇考試板的文章、20篇ptt板的文章

### 將文章資料合在一起
```{r}
#透過rbind將文章資料合起來
article = nsysu_data %>%
   select(id,createdAt ,source ,title,content)%>% 
   rbind(nuk_data %>% select(id,createdAt ,source ,title,content))%>%
   rbind(exam_data %>% select(id,createdAt ,source ,title,content))
colname = c("id", "artDate","source","artTitle","artContent")
colnames(article) <- colname
article = article %>%
  rbind(ptt_data %>% select(id,artDate ,source ,artTitle,artContent))
article$artDate = as.Date(article$artDate)
kable(article) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```



### 整理留言資料
- 留言資料為過濾完的文章資料下面的留言
```{r}
nsysu_comment = nsysu_comment %>%
  filter(nchar(nsysu_comment$content)>5)%>% 
  mutate(source="nsysu_dcard")
 nuk_comment = nuk_comment %>%
  filter(nchar(nuk_comment$content)>5)%>% 
   mutate(source="nuk_dcard")
 exam_comment = exam_comment %>%
  filter(nchar(exam_comment$content)>5)%>% 
  mutate(source="exam_dcard")
ptt_comment = ptt_comment %>%
  filter(nchar(ptt_comment$content)>5)%>% 
  mutate(source="ptt")
```

### 將留言資料合在一起
```{r}
comment = nsysu_comment %>%
   select(id,Date ,source ,source,content)%>% 
   rbind(nuk_comment %>% select(id,Date ,source ,content))%>%
  rbind(exam_comment %>% select(id,Date ,source ,content))
comment =comment %>%
  rbind(ptt_comment %>% select(id,Date ,source ,source,content))
colname = c("id", "artDate","source","artContent")
colnames(comment) <- colname
comment$artDate = as.Date(comment$artDate)
comment <- comment %>% 
  filter(id %in% article$id)
kable(comment) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```

### 將留言資料和文章資料合起來
```{r}
data = article%>%
  smartbind(comment)
kable(data) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```


### 以日期計算文章數
```{r}
data_count_by_date <- data %>% 
  group_by(artDate,source) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))

kable(head(data_count_by_date, 20)) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")

```

### 畫出日期以及文章分布折線圖 
```{r message=FALSE, warning=FALSE}
plot_date <- 
  data_count_by_date %>% 
  ggplot(aes(x = as.Date(artDate), y = count,colour=source)) +
  geom_line(size = 0.5) + 
  # geom_vline(xintercept = as.numeric(as.Date("2019-03-30")), col='red') + 
  scale_x_date(labels = date_format("%Y/%m/%d" )) +
  ggtitle("高大與中山併校 討論文章數") + 
  xlab("日期") + 
  ylab("數量") + 
  theme(text = element_text(family = "Heiti TC Light")) #加入中文字型設定，避免中文字顯示錯誤。

plot_date
```

- 可以看到在三月底四月初時，有明顯熱烈討論的現象，因當時中山大學校方正在積極與高雄大學討論合併的事情，同時也展開公聽會等，讓大家可以更了解併校

### 增加結巴字典以及正規化function已得到tokens
```{r}
jieba_tokenizer <- worker(user="dict/user_dict.txt", stop_word = "dict/stop_words.txt")
clean = function(txt) {
  txt = gsub("B\\w+", "", txt) #去除@或#後有數字,字母,底線 (標記人名或hashtag)
  txt = gsub("(http|https)://.*", "", txt) #去除網址
  txt = gsub("[ \t]{2,}", "", txt) #去除兩個以上空格或tab
  txt = gsub("\\n"," ",txt) #去除換行
  txt = gsub("\\s+"," ",txt) #去除一個或多個空格
  txt = gsub("^\\s+|\\s+$","",txt) #去除前後一個或多個空格
  txt = gsub("&.*;","",txt) #去除html特殊字元編碼
  txt = gsub("[a-zA-Z0-9?!. ']","",txt) #除了字母,數字 ?!. ,空白的都去掉
  txt }
tokenizer <- function(t) {
  lapply(t, function(x) {
    tokens <- segment(x, jieba_tokenizer)
    return(tokens)
  })
}
data_tokens <- data %>% 
  unnest_tokens(word, artContent, token=tokenizer)
data_tokens$word = clean(data_tokens$word)
data_tokens = data_tokens %>%
  filter(!word == "")
```

### 計算詞彙的出現次數，如果詞彙只有一個字則不列入計算
```{r}
data_tokens_count <- data_tokens %>% 
  filter(nchar(.$word)>1) %>%
  group_by(word) %>% 
  summarise(sum = n()) %>% 
  filter(sum>1) %>%
  arrange(desc(sum))
# 印出最常見的20個詞彙
kable(head(data_tokens_count,20)) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```

- 可以看到出現頻率高的字不外乎為中山、中山大學、併校、合併、高雄大學等等，令人感到神奇的是高醫，由於高醫之前也有在討論是否要併校，所以大家主要比較的對象，故頻率出現也較高

### 文字雲
```{r}
#data_tokens_count %>% wordcloud2()
```
![](img/wordcloud_tokens.PNG) 

- 在文字雲當中，我們可以看到一些與併校十分相關的詞彙，像是科系、法學院、畢業證書等等，可以看出在社群媒體中，主要留言的為學生，比較重視自己的利益


### 過濾主題字查看常出現的詞彙
- 將前面出現主題字過濾掉看一下詞彙，因為主題的詞彙，對我們來說，沒有什麼訊息
```{r}
data_tokens_count %>%
  filter(!word %in% c("中山","大學","中山大學","高大","學校","高雄大學","國立","合校"))%>%
  mutate(word = reorder(word, sum)) %>%
  top_n(25,sum) %>%
  ggplot(aes(word, sum)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```

- 可以看到高醫的比率以及校區、科系、畢業證書、企業等等，都是切身相關學生的議題

### 探討dcard上高大同學以及中山同學對於併校的看法
```{r}
student_dcard = data_tokens%>%
  filter(source %in% c("nsysu_dcard","nuk_dcard"))
  
student_dcard%>%
  group_by(source) %>% 
  summarise(sum = n()) %>%
  ggplot(aes(source,
             sum))+ 
  geom_bar(stat="identity", width=0.5,fill="steelblue")+
  geom_text(aes(label=sum), vjust=-0.3, size=3.5)
```

- 兩邊的文章+留言數 數量為9178筆以及6787筆
### 計算詞彙在中山dcard版及高大dcard版出現比率的差異
```{r}
frequency <- student_dcard%>%
  dplyr::count(source, word)%>%
  group_by(source) %>%
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  spread(source, proportion) %>% 
  gather(source, proportion, `nuk_dcard`)
kable(head(frequency,100)) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```

- 計算詞彙在中山dcard版及高大dcard版出現比率的差異

### 繪製出詞彙在中山dcard版及高大dcard版出現比率的差異
```{r message=FALSE, warning=FALSE}
ggplot(frequency, aes(x = proportion, y = `nsysu_dcard`, color = abs(`nsysu_dcard` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.2, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75")+
  theme(legend.position="none") +
  labs(y = "nsysu_dcard", x = "nuk_dcard")
```

- 根據上圖，可以看出中山的dcard板比較常出現的詞彙有西子灣、校務、土地、增加、公聽會，我認為主要為中山校方當時在準備舉辦公聽會，而中山學生主要在意的是若是合併，最大的好處應該是增加土地。
- 根據上圖，可以看到高大的dcard板比較常出現的詞彙有企業、工作、能力等等，我認為是他們的學生主要探討的是若是和中山合併，他們在企業會大大的加分，可以得到更好的工作，但是也要考慮自己的能力等等的。

### 計算中山dcard以及高大dcard詞彙相關係數
```{r}
cor.test(data = frequency[frequency$source == "nuk_dcard",],
         ~ proportion + `nsysu_dcard`)
```
- 相關性算是偏高，應該是因為兩邊在探討一樣的議題，所使用的詞彙都差不多

### 準備LIWC中文情緒字典 
```{r}
p <- read_file("dict/positive.txt")
n <- read_file("dict/negative.txt")
positive <- strsplit(p, "[,]")[[1]]
negative <- strsplit(n, "[,]")[[1]]
positive <- data.frame(word = positive, sentiments = "positive")
negative <- data.frame(word = negative, sentiemtns = "negative")
colnames(negative) = c("word","sentiment")
colnames(positive) = c("word","sentiment")
LIWC_ch <- rbind(positive, negative)
kable(head(LIWC_ch,100)) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```

### 使用LIWC中文情緒字典應用於中山及高大dcard版詞彙
```{r message=FALSE, warning=FALSE}
sentiment_dcard = student_dcard %>%
   filter(nchar(.$word)>1) %>%
  group_by(source,word) %>% 
  summarise(sum = n()) %>% 
  filter(sum>1) %>%
  arrange(desc(sum))%>%
  inner_join(LIWC_ch)


kable(sentiment_dcard) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```

### 繪製出圖表
```{r}
plot_table<-sentiment_dcard %>%
  group_by(source,sentiment) %>%
  summarise(count=sum(sum)) 
# interaction(source, sentiment)
plot_table %>%
  ggplot(aes( sentiment,count,fill=sentiment))+
  geom_bar(stat="identity", width=0.5)+
  facet_grid(~source)
```

- 看不出有什麼明顯的差異，等等會加入新的自定義字典

### 查看正面以及負面的情緒字
```{r message=FALSE, warning=FALSE}
student_dcard %>% 
  count(word)%>%
  inner_join(LIWC_ch) %>%
  group_by(sentiment) %>%
  top_n(10,wt = n) %>%
  ungroup() %>% 
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  theme(text=element_text(size=14))+
  coord_flip()
```

- 可以看出在正面、負面詞較常出現的詞彙

### 新增對於中山的學生正面及負面字典
- 新增負面字: 排名,畢業證書,經費,資源,分數,學店,距離,比較,補助,名字,素質,傻眼,競爭力,學歷,證書,改名,競爭,世界排名,科系,問題 
- 新增正面字:校地,法律系,法學院,擴張,期待,開心,好處,成功,支持,想要,增加,利益,課程,進步,擴展,正面,值得,一流
```{r}
p <- read_file("dict/nsysu_positive.txt")
n <- read_file("dict/nsysu_negative.txt")
positive <- strsplit(p, "[,]")[[1]]
negative <- strsplit(n, "[,]")[[1]]
positive <- data.frame(word = positive, sentiments = "positive")
negative <- data.frame(word = negative, sentiemtns = "negative")
colnames(negative) = c("word","sentiment")
colnames(positive) = c("word","sentiment")
nsysu_ch <- rbind(positive, negative)
#中山自定義字典
kable(head(nsysu_ch,100)) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")

```

### 將字典應用到中山dcard板詞彙並畫圖
```{r message=FALSE, warning=FALSE}
sentiment_dcard = student_dcard %>%
   filter(nchar(.$word)>1) %>%
  group_by(source,word) %>% 
  summarise(sum = n()) %>% 
  filter(sum>1) %>%
  arrange(desc(sum))%>%
  filter(source =="nsysu_dcard")%>%
  inner_join(nsysu_ch)
plot_table<-sentiment_dcard %>%
  group_by(source,sentiment) %>%
  summarise(count=sum(sum)) 
plot_table %>%
  ggplot(aes( sentiment,count,fill=sentiment))+
  geom_bar(stat="identity", width=0.5)
```

- 可以看初中山dcard板的負面大於正面，主要是因為討論的內容對於中山的學生來說，主要都是會因為高大的排名或是分數等等的會讓中山的名氣下降，故負面大於正面

### 查看正面以及負面的情緒字
```{r message=FALSE, warning=FALSE}
student_dcard %>% 
  filter(source=="nsysu_dcard")%>%
  count(word)%>%
  inner_join(nsysu_ch) %>%
  group_by(sentiment) %>%
  top_n(10,wt = n) %>%
  ungroup() %>% 
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  theme(text=element_text(size=14))+
  coord_flip()
```

- 在正面字當中，可以看到法律系、增加校地等，這些為主要若是合併後，高大能夠提供給中山的幾個好處。
- 在負面字當中，可以看到問題、科系、排名、畢業證書，可以看到若是合併對於中山的影響有分很多方面，也同時會引起很多問題。

### 新增對於高大的學生正面及負面字典

- 正面字:企業,畢業,校名,畢業證書,排名,學歷,經費,想要,資源,升級,四大,願意,成功,競爭力,擴張,土地,期待,開心,好處,優勢
- 負面字:不想,猴子,問題,學店,無聊,看不起,抱歉,不想,傻眼,距離,歧視,可憐,延畢,垃圾,貶低,
```{r}
p <- read_file("dict/nuk_positive.txt")
n <- read_file("dict/nuk_negative.txt")
positive <- strsplit(p, "[,]")[[1]]
negative <- strsplit(n, "[,]")[[1]]
positive <- data.frame(word = positive, sentiments = "positive")
negative <- data.frame(word = negative, sentiemtns = "negative")
colnames(negative) = c("word","sentiment")
colnames(positive) = c("word","sentiment")
nuk_ch <- rbind(positive, negative)

kable(head(nuk_ch,100)) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")

```

### 將字典應用到高大dcard板詞彙並畫圖
```{r message=FALSE, warning=FALSE}
sentiment_dcard = student_dcard %>%
   filter(nchar(.$word)>1) %>%
  group_by(source,word) %>% 
  summarise(sum = n()) %>% 
  filter(sum>1) %>%
  arrange(desc(sum))%>%
  filter(source=="nuk_dcard")%>%
  inner_join(nuk_ch)
plot_table<-sentiment_dcard %>%
  group_by(source,sentiment) %>%
  summarise(count=sum(sum)) 
plot_table %>%
  ggplot(aes( sentiment,count,fill=sentiment))+
  geom_bar(stat="identity", width=0.5)
```

- 可以看到高大dcard板所呈現的情緒為正面大於負面的，主要是因為，他們所談論的詞彙主要都是對他們來說是正面效益的詞彙，根據情緒，可以推估他們會比較想要併校。

### 查看正面以及負面的情緒字
```{r message=FALSE, warning=FALSE}
student_dcard %>% 
  filter(source=="nuk_dcard")%>%
  count(word)%>%
  inner_join(nuk_ch) %>%
  group_by(sentiment) %>%
  top_n(10,wt = n) %>% 
  ungroup() %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  theme(text=element_text(size=14))+
  coord_flip()
```

- 可以看出 對於高大的學生正面的詞彙有企業、校名、畢業證書、排名，這些對於學生來說是切身相關的資訊，而負面則有問題、學店、看不起等等詞彙。

### ngram

### bigram function
```{r}
# remove stopwords
# unnest_tokens 使用的bigram分詞函數
# Input: a character vector
# Output: a list of character vectors of the same length
jieba_bigram <- function(t) {
  lapply(t, function(x) {
    if(nchar(x)>1){
      tokens <- segment(x, jieba_tokenizer)
      bigram<- ngrams(tokens, 2)
      bigram <- lapply(bigram, paste, collapse = " ")
      unlist(bigram)
    }
  })
}
```

### 執行bigram斷詞
```{r}
article_comment <- article %>% 
  smartbind(comment)
article_comment_bigram <- article_comment %>%
  unnest_tokens(bigram, artContent, token = jieba_bigram)
kable(head(article_comment_bigram, 100)) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```

### 載入各種字典
```{r message=FALSE, warning=FALSE}
# load devotion_lexicon
user_dict <- scan(file = "./dict/user_dict.txt", what=character(),sep='\n', 
                   encoding='utf-8',fileEncoding='utf-8')
stop_words_df <- fread(file = "./dict/stop_words.txt", sep='\n'
                   ,encoding='UTF-8', colClasses="character")
stop_words <- stop_words_df %>% pull(1)
negation_words <- scan(file = "./dict/negation_words.txt", what=character(),sep='\n')
```

### ngram 結合 情緒分析
```{r}
# 將bigram拆成word1和word2
# 將包含英文字母或和數字的詞彙清除
bigrams_separated <- article_comment_bigram %>%
  filter(!str_detect(bigram, regex("[0-9a-zA-Z]"))) %>%
  separate(bigram, c("word1", "word2"), sep = " ")
# 並選出word2爲情緒詞的bigram
#去除wrod1與word2都是stop word
bigrams_separated  <- bigrams_separated %>%
  filter(!(word1 %in% stop_words & word2 %in% stop_words)) 

article_comment_sentiment_bigrams <- rbind(
  bigrams_separated %>% 
    filter(source == "nsysu_dcard") %>% 
    merge(nsysu_ch , by.x='word2', by.y='word')
  ,
  bigrams_separated %>% 
    filter(source == "nuk_dcard") %>% 
    merge(nuk_ch , by.x='word2', by.y='word')
  ,
  bigrams_separated %>% 
    filter(source == "ptt" | source == "exam_dcard") %>% 
    merge(LIWC_ch , by.x='word2', by.y='word')
)    
article_comment_sentiment_bigrams <- article_comment_sentiment_bigrams %>% select(id,	 artDate,	 source,	 artTitle,	 word1, word2,	 sentiment)


kable(article_comment_sentiment_bigrams) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```

### 將positive與negative給予情緒值
```{r}
# 選出word2中，有出現在情緒詞典中的詞彙
# 如果是正面詞彙則賦予： 情緒標籤爲"positive"、情緒值爲  1
# 如果是負面詞彙則賦予： 情緒標籤爲"negative"、情緒值爲 -1
#將正負面詞分開
article_comment_sentiment_bigrams <- article_comment_sentiment_bigrams %>% rename(sentiment_tag = sentiment)
article_comment_sentiment_bigrams <- article_comment_sentiment_bigrams %>% 
  mutate(sentiment = ifelse(sentiment_tag == "positive",1,-1)) %>%
  select(source, artDate, word1, word2, sentiment_tag, sentiment)
  
kable(article_comment_sentiment_bigrams) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```

### 繪製情緒走勢圖
```{r}
# 生成一個時間段中的 日期和情緒標籤的所有可能組合
all_dates <- 
  expand.grid(seq(as.Date(min(article_comment_sentiment_bigrams$artDate)), as.Date(max(article_comment_sentiment_bigrams$artDate)), by="day"), c("positive", "negative"))
names(all_dates) <- c("artDate", "sentiment")

# 計算我們資料集中 每日的情緒值
sentiment_plot_data <- article_comment_sentiment_bigrams %>%
  group_by(artDate,sentiment_tag) %>%
  summarise(count=n())  
# 將所有 "日期與情緒值的所有可能組合" 與 "每日的情緒值" join起來
# 如果資料集中某些日期沒有文章或情緒值，會出現NA
# 我們用0取代NA
sentiment_plot_data <- all_dates %>% 
  merge(sentiment_plot_data,by.x=c('artDate', "sentiment"),by.y=c('artDate', "sentiment_tag"),
        all.x=T,all.y=T) %>% 
  mutate(count = replace_na(count, 0))

# 畫圖
sentiment_plot_data %>%
  ggplot()+
  geom_line(aes(x=artDate,y=count,colour=sentiment), size = 1.2)+
  scale_x_date(labels = date_format("%m/%d")) 
```

- 從情緒走勢圖可以看到正面情緒有兩個高峰，第一個高峰是2月初，第二個是在4月初；負面情緒則可發現是在4月初後大幅提高。2月初高峰原因在於有中山教授演講表明高大與中山會於2~3年之內合併。4月初後期，不論正負面情緒都大幅增加，原因是由於中山校方積極展開併校評估以及公聽會。

### 各來源的情緒走勢圖

```{r}
# 計算我們資料集中 每日的情緒值
source_sentiment_plot_data <- article_comment_sentiment_bigrams %>%
  group_by(source, artDate,sentiment_tag) %>%
  summarise(count=n())  
# 將所有 "日期與情緒值的所有可能組合" 與 "每日的情緒值" join起來
# 如果資料集中某些日期沒有文章或情緒值，會出現NA
# 我們用0取代NA
source_sentiment_plot_data <- rbind(
  all_dates %>% 
  merge(source_sentiment_plot_data %>% 
          filter(source == "nsysu_dcard")
        ,by.x=c('artDate', "sentiment"),by.y=c('artDate', "sentiment_tag"),
        all.x=T,all.y=T) %>% 
  mutate(source = "nsysu_dcard"), 
  all_dates %>% 
  merge(source_sentiment_plot_data %>% 
          filter(source == "nuk_dcard")
        ,by.x=c('artDate', "sentiment"),by.y=c('artDate', "sentiment_tag"),
        all.x=T,all.y=T) %>% 
  mutate(source = "nuk_dcard"), 
  all_dates %>% 
  merge(source_sentiment_plot_data %>% 
          filter(source == "exam_dcard")
        ,by.x=c('artDate', "sentiment"),by.y=c('artDate', "sentiment_tag"),
        all.x=T,all.y=T) %>% 
  mutate(source = "exam_dcard"), 
  all_dates %>% 
  merge(source_sentiment_plot_data %>% 
          filter(source == "ptt")
        ,by.x=c('artDate', "sentiment"),by.y=c('artDate', "sentiment_tag"),
        all.x=T,all.y=T) %>% 
  mutate(source = "ptt") 
  ) %>% 
  mutate(count = replace_na(count, 0))

# 畫圖
source_sentiment_plot_data %>%
  ggplot()+
  geom_line(aes(x=artDate,y=count,colour=sentiment))+
  scale_x_date(labels = date_format("%m/%d")) + 
  facet_wrap(~source)
```

- 從高大Dcard來源來看，可以看到2月初正面情緒值非常高，原因在於高大學生得知併校消息，部分學生希望能延畢，拿到中山的畢業證書。此外2月也釋出了2019年企業愛用的大學排行，而排行中有中山大學，導致學生們更希望與中山併校，因此正面情緒值很高。不過在4月初可以發現負面情緒值提高，原因在於部分高大學生認為中山是覬覦高大的法律系，以及，高大學生不希望合併後是用中山的校名，因此對中山有不少負面言論。
- 從中山Dcard來源來看，可以看到負面情緒大多都比正面情緒多，因為大部分中山的學生不希望與高大合併，擔心學校排名下降、畢業證書變得不值錢等，除此之外，中山學生由於看到高大板充滿攻擊中山的言論，導致兩校學生相互批評，這也導致負面情緒值變高。

### 使用否定詞改變詞彙情緒值
```{r}
# 查看 前面出現否定詞 且 後面爲情緒詞彙 的組合
kable(article_comment_sentiment_bigrams %>%
  filter(word1 %in% negation_words) %>%
  count(word1, word2, sort = TRUE) ) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")

```

```{r}
# 如果在情緒詞前出現的是否定詞的話，則將他的情緒對調
article_comment_sentiment_bigrams_negated <- article_comment_sentiment_bigrams %>%
  mutate(sentiment=ifelse(word1 %in% negation_words, -1*sentiment, sentiment)) %>%
  mutate(sentiment_tag=ifelse(sentiment>0, "positive", "negative"))
kable(article_comment_sentiment_bigrams_negated) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```

### 繪製否定詞改變後的情緒走勢圖
```{r}
# 計算我們資料集中 每日的情緒值
negated_sentiment_plot_data <- article_comment_sentiment_bigrams_negated %>%
  group_by(artDate,sentiment_tag) %>%
  summarise(count=n())  
# 將所有 "日期與情緒值的所有可能組合" 與 "每日的情緒值" join起來
# 如果資料集中某些日期沒有文章或情緒值，會出現NA
# 我們用0取代NA
negated_sentiment_plot_data <- all_dates %>% 
  merge(negated_sentiment_plot_data,by.x=c('artDate', "sentiment"),by.y=c('artDate', "sentiment_tag"),
        all.x=T,all.y=T) %>% 
  mutate(count = replace_na(count, 0))
# 最後把圖畫出來
negated_sentiment_plot_data %>%
  ggplot()+
  geom_line(aes(x=artDate,y=count,colour=sentiment), size = 1.2)+
  scale_x_date(labels = date_format("%m/%d")) 
```

### 各來源否定詞改變後的情緒走勢圖
```{r}
# 計算我們資料集中 每日的情緒值
source_negated_sentiment_plot_data <- article_comment_sentiment_bigrams_negated %>%
  group_by(source, artDate,sentiment_tag) %>%
  summarise(count=n())  
# 將所有 "日期與情緒值的所有可能組合" 與 "每日的情緒值" join起來
# 如果資料集中某些日期沒有文章或情緒值，會出現NA
# 我們用0取代NA
source_negated_sentiment_plot_data <- rbind(
  all_dates %>% 
  merge(source_negated_sentiment_plot_data %>% 
          filter(source == "nsysu_dcard")
        ,by.x=c('artDate', "sentiment"),by.y=c('artDate', "sentiment_tag"),
        all.x=T,all.y=T) %>% 
  mutate(source = "nsysu_dcard"), 
  all_dates %>% 
  merge(source_negated_sentiment_plot_data %>% 
          filter(source == "nuk_dcard")
        ,by.x=c('artDate', "sentiment"),by.y=c('artDate', "sentiment_tag"),
        all.x=T,all.y=T) %>% 
  mutate(source = "nuk_dcard"), 
  all_dates %>% 
  merge(source_negated_sentiment_plot_data %>% 
          filter(source == "exam_dcard")
        ,by.x=c('artDate', "sentiment"),by.y=c('artDate', "sentiment_tag"),
        all.x=T,all.y=T) %>% 
  mutate(source = "exam_dcard"), 
  all_dates %>% 
  merge(source_negated_sentiment_plot_data %>% 
          filter(source == "ptt")
        ,by.x=c('artDate', "sentiment"),by.y=c('artDate', "sentiment_tag"),
        all.x=T,all.y=T) %>% 
  mutate(source = "ptt") 
  ) %>% 
  mutate(count = replace_na(count, 0))
# 畫圖
source_negated_sentiment_plot_data %>%
  ggplot()+
  geom_line(aes(x=artDate,y=count,colour=sentiment))+
  scale_x_date(labels = date_format("%m/%d")) + 
  facet_wrap(~source)
```

### 比較否定詞相反情緒值後的情緒走勢
```{r}
# 合併兩種情緒值的資料
all_sentiments <- bind_rows(
  sentiment_plot_data %>% mutate(sentiment=paste(sentiment, "_original", sep = "")),
  negated_sentiment_plot_data %>% mutate(sentiment=paste(sentiment, "_negated", sep = ""))) 
kable(all_sentiments) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```

```{r}
# 先比較正面情緒
all_sentiments %>% 
  filter(sentiment %in% c("positive_negated", "positive_original")) %>% 
  ggplot()+
  geom_line(aes(x=artDate,y=count,colour=sentiment))+
  scale_x_date(labels = date_format("%m/%d")) 

```

- 正面情緒與原先結果差異不大

```{r}
# 再比較負面情緒
all_sentiments %>% 
  filter(sentiment %in% c("negative_original", "negative_negated")) %>%
  ggplot()+
  geom_line(aes(x=artDate,y=count,colour=sentiment))+
  scale_x_date(labels = date_format("%m/%d")) 
```

- 負面情緒與原先結果差異不大

### 比較各來源否定詞相反情緒值後的情緒走勢
```{r}
# 合併兩種情緒值的資料
all_sentiments <- bind_rows(
  source_sentiment_plot_data %>% mutate(sentiment=paste(sentiment, "_original", sep = "")),
  source_negated_sentiment_plot_data %>% mutate(sentiment=paste(sentiment, "_negated", sep = ""))) 
kable(all_sentiments) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```

```{r}
# 先比較正面情緒
all_sentiments %>% 
  filter(sentiment %in% c("positive_original", "positive_negated")) %>%
  ggplot()+
  geom_line(aes(x=artDate,y=count,colour=sentiment))+
  scale_x_date(labels = date_format("%m/%d")) +
  facet_wrap(~source)
```

- 正面情緒與原先結果差異不大

```{r}
# 再比較負面情緒
all_sentiments %>% 
  filter(sentiment %in% c("negative_original", "negative_negated")) %>%
  ggplot()+
  geom_line(aes(x=artDate,y=count,colour=sentiment))+
  scale_x_date(labels = date_format("%m/%d")) + 
  facet_wrap(~source)
```

- 負面情緒與原先結果差異不大

### 11gram - 尋找特定詞彙的前後5個詞彙
```{r}
# ngram function, where n=11
ngram_11 <- function(t) {
  lapply(t, function(x) {
    if(nchar(x)>1){
      tokens <- segment(x, jieba_tokenizer)
      ngram<- ngrams(tokens, 11)
      ngram <- lapply(ngram, paste, collapse = " ")
      unlist(ngram)
    }
  })
}
```

```{r}
# 執行ngram_11進行分詞
article_comment_ngram_11 <- article_comment %>%
  select(id, artContent) %>%
  unnest_tokens(ngram, artContent, token = ngram_11) %>%
  filter(!str_detect(ngram, regex("[0-9a-zA-Z]")))
```
```{r}
# 將ngram拆成word1 ~ word11
ngrams_11_separated <- article_comment_ngram_11 %>%
  separate(ngram, paste0("word", c(1:11),sep=""), sep = " ")
  
kable(ngrams_11_separated) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```

### 尋找 "中山" 出現的前後五個詞彙
```{r}
# 尋找 "中山" 出現的前後五個詞彙
tu_five_words <- ngrams_11_separated %>%
  filter((word6=="中山"))
kable(tu_five_words) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```


```{r}
# 尋找 "中山" 的前後5個詞中常出現哪些的詞彙
tu_five_words_count <- tu_five_words %>%
  melt(id.vars = "id", measure.vars = paste0("word", c(1:11),sep="")) %>%
  rename(word=value) %>%
  filter(variable!="word6") %>%
  filter(!(word %in% stop_words), nchar(word)>1) %>%
  count(word, sort = TRUE)
kable(tu_five_words_count) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```

```{r message=FALSE, warning=FALSE}
# 畫圖顯示
tu_five_words_count %>%
  arrange(desc(abs(n))) %>%
  head(20) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = n > 0)) +
  geom_col(show.legend = FALSE) +
  xlab("Words near by \"中山") +
  ylab("Word count") +
  coord_flip()+ 
  theme(text = element_text(family = "Heiti TC Light")) #加入中文字型設定，避免中文字顯示錯誤。
```

- 從長條圖可以看到中山前後常出現高大、高醫與中山，由於是中山可能併的學校，因此常一起出現。
- 從此之外，其他詞彙，像是:資源、校區、西子灣以及仁武，就是偏向討論中山的校地資源，推測可能是討論校地資源不足跟併校的關聯性。

### Word Correlation
```{r}
# 計算兩個詞彙同時出現的總次數
id_data_tokens <- data_tokens %>%
  count(id, word, sort = TRUE) 
word_pairs <- id_data_tokens %>%
  pairwise_count(word, id, sort = TRUE)
kable(head(word_pairs, 100)) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```
- 結果跟想像的一樣，兩詞彙一起出現的次數多的都是與學校、併校有關。

```{r}
# 計算兩個詞彙間的相關性
word_cors <- id_data_tokens %>%
  group_by(word) %>%
  filter(n() >= 20) %>%
  pairwise_cor(word, id, sort = TRUE)
kable(head(word_cors,20)) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```
- 結果除了部分與word pairs一樣，有些不太一樣，像是:教育部與高醫，推論可能是中山大學是國立的，希望與私立的高醫併校，因此希望教育部能鬆綁限制。

```{r}
# 顯示相關性大於0.398的組合
set.seed(2019)
word_cors %>%
  filter(correlation > .398) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
  geom_node_point(color = "lightblue", size = 3) +
  geom_node_text(aes(label = name), repel = TRUE, family = "Heiti TC Light") + #加入中文字型設定，避免中文字顯示錯誤。
  theme_void()
```

- 主要分兩大群，中間下面這群主要是與學校、併校有關，因為有出現像是:高大、高醫、併校等詞彙
- 左上角這群主要是跟中山學生的擔心有關，因為出現詞彙像是:分數、排名與畢業。中山學生擔心的在於不希望中山的排名下降，也不希望學生用比較高的分數進來中山，畢業後卻與高大領一樣的畢業證書

### 計算tf-idf找出各來源討論中較獨特的詞彙
```{r}
#計算各來源的總詞彙數
data_tokens_count <- data_tokens %>% 
  count(source, word)
total_words_counts <- data_tokens_count %>% 
  group_by(source) %>% 
  summarise(total = sum(n))
total_words <- left_join(data_tokens_count, total_words_counts)
#bind tf-idf
total_words_tf_idf <- total_words %>%
  bind_tf_idf(word, source, n)
kable(total_words_tf_idf ) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```

### 依照各來源列出tf-idf前十高的詞彙繪製長條圖
```{r message=FALSE, warning=FALSE}
total_words_tf_idf %>% 
  group_by(source) %>% 
  top_n(10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, tf_idf)) %>% 
  ggplot(aes(word, tf_idf, fill = source)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~source, ncol = 2, scales = "free") +
  coord_flip()
```

- 在不同來源可以看到一些特別的詞彙。
- 考試板因為會與各個學校比較，所以出現不少學校的名字，像是:北商、國北教、東華...等
- 中山板因為談論到與高醫併校，因此有許多高醫相關的詞彙，像是:校董、校友會，此外也有中山併校本身相關的，像是西子灣、擴張等
- 高大板因為如上面所述，因中山屬於企業愛用的大學，因此希望併校，所以內容有關職場
- ptt則大多是新聞，所以談論到蔡秀芬副校長的聲明，中山設立醫學系的相關討論，像是大學讀基礎科學，研究所再讀醫學系等討論

### 各來源詞彙比例與詞頻長條圖
```{r message=FALSE, warning=FALSE}
ggplot(total_words, aes(n/total, fill = source)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.01) +
  facet_wrap(~source, ncol = 2, scales = "free_y")
```

- 各來源詞彙比例分布型態相近

### 討論併校的文章是否符合zip'f law
```{r}
freq_by_rank <- total_words %>% 
  group_by(source) %>% 
  arrange(desc(n)) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total)

kable(freq_by_rank) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")

freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = source)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()
```

### 依照lm模型結果繪製虛線
```{r}
rank_subset <- freq_by_rank %>% 
  filter(rank < 500,
         rank > 10)
lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)
freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = source)) + 
  geom_abline(intercept = -1.417  , slope = -0.730, color = "gray50", linetype = 2) +
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()
```

- 大致上符合zip'f law